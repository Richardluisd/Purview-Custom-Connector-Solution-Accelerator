{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "blob_container_name = \"\"\r\n",
        "blob_account_name = \"\"\r\n",
        "blob_relative_path = \"\"\r\n",
        "app_name = \"\"\r\n",
        "purview_name = \"\"\r\n",
        "TENANT_ID = \"\"\r\n",
        "CLIENT_ID = \"\"\r\n",
        "CLIENT_SECRET = \"\"\r\n",
        "blob_processed=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import json\r\n",
        "import os\r\n",
        "import sys\r\n",
        "from pyspark.sql.types import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "\r\n",
        "# PyApacheAtlas packages\r\n",
        "# Connect to Atlas via a Service Principal\r\n",
        "from pyapacheatlas.auth import ServicePrincipalAuthentication\r\n",
        "from pyapacheatlas.core import PurviewClient, AtlasClassification, AtlasEntity, AtlasProcess, RelationshipTypeDef  # Communicate with your Atlas server\r\n",
        "from pyapacheatlas.readers import ExcelConfiguration, ExcelReader\r\n",
        "from pyapacheatlas.core.util import GuidTracker,AtlasException\r\n",
        "from pyapacheatlas.core import AtlasAttributeDef, AtlasEntity, PurviewClient\r\n",
        "from pyapacheatlas.core.typedef import EntityTypeDef\r\n",
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "from pyspark.conf import SparkConf\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "my_jars = os.environ.get(\"SPARK_HOME\")\r\n",
        "myconf = SparkConf()\r\n",
        "myconf.setMaster(\"local\").setAppName(app_name)\r\n",
        "myconf.set(\"spark.jars\",\"%s/jars/log4j-1.2.17.jar\" % my_jars)\r\n",
        "spark = SparkSession\\\r\n",
        " .builder\\\r\n",
        " .appName(app_name)\\\r\n",
        " .config(conf = myconf) \\\r\n",
        " .getOrCreate()\r\n",
        "\r\n",
        "\r\n",
        "Logger= spark._jvm.org.apache.log4j.Logger\r\n",
        "mylogger = Logger.getLogger(app_name)\r\n",
        "adls_home = 'abfss://%s@%s.dfs.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\r\n",
        "adls_processed = 'abfss://%s@%s.dfs.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def log_msgs(msg_type,msg):\r\n",
        "        \r\n",
        "        if msg_type.upper() == \"ERROR\":\r\n",
        "            print('ERROR: %s' % repr(msg))\r\n",
        "            mylogger.error(repr(msg))\r\n",
        "        else:\r\n",
        "            print('INFO: %s' % repr(msg))\r\n",
        "            mylogger.info(repr(msg))\r\n",
        "           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "    # Authenticate against your Atlas server\r\n",
        "oauth = ServicePrincipalAuthentication(\r\n",
        "       tenant_id= TENANT_ID, \r\n",
        "       client_id=CLIENT_ID, \r\n",
        "       client_secret=CLIENT_SECRET \r\n",
        "  )\r\n",
        "client = PurviewClient(\r\n",
        "        account_name = os.environ.get(\"PURVIEW_NAME\", purview_name),\r\n",
        "        authentication=oauth\r\n",
        "    )\r\n",
        "gt = GuidTracker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def Get_Rel_Inputs(json_obj):\r\n",
        "    try:\r\n",
        "        att_value = json_obj['relationshipAttributes']['inputs']\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False\r\n",
        "\r\n",
        "def Get_Rel_Outputs(json_obj):\r\n",
        "    try:\r\n",
        "        att_value = json_obj['relationshipAttributes']['outputs']\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False\r\n",
        "\r\n",
        "def Get_Outputs(json_obj):\r\n",
        "    try:\r\n",
        "        att_value = json_obj['attributes']['outputs']\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False\r\n",
        "\r\n",
        "def Get_Inputs(json_obj):\r\n",
        "    try:\r\n",
        "        att_value = json_obj['attributes']['inputs']\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False\r\n",
        "def Get_Rel_Parents(json_obj):\r\n",
        "    try:\r\n",
        "        att_value = json_obj['relationshipAttributes']['parent']\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def search_entities_byQuilifiedName(name):\r\n",
        "    results = client.search_entities('qualifiedName\\:%s' % name.replace(\":\",\"\\:\").replace(\"/\",\"\\/\").replace(\"{\",\"\\{\").replace(\"}\",\"\\}\"))\r\n",
        "    guid = None\r\n",
        "    for result in results:\r\n",
        "        if result['qualifiedName'] == name:\r\n",
        "                guid= result['id']\r\n",
        "                if result['entityType'] != 'purview_custom_connector_generic_entity':\r\n",
        "                    #print(result)\r\n",
        "                    break\r\n",
        "    return guid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def removeDummyEntity(name):\r\n",
        "    try:\r\n",
        "        results = client.search_entities('qualifiedName\\:%s' % name.replace(\":\",\"\\:\").replace(\"/\",\"\\/\"))\r\n",
        "        for result in results:\r\n",
        "            if result['qualifiedName'] ==name:\r\n",
        "                entity = client.get_entity(guid=result['id'])\r\n",
        "                if len(entity['entities']) > 0 :\r\n",
        "                    if len(entity['entities'][0]['relationshipAttributes']['inputToProcesses']) == 0 and len(entity['entities'][0]['relationshipAttributes']['outputFromProcesses']) == 0:\r\n",
        "                        log_msgs(\"INFO\",'removeDummyEntity: Deleted Dummy entity%s' % (entity['entities'][0]))\r\n",
        "                        client.delete_entity(entity['entities'][0]['guid'])\r\n",
        "    except:\r\n",
        "        log_msgs(\"ERROR\",'Build_Entity_Json: %s' % (str(e)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def Create_Generic_Entity(dummy):\r\n",
        "    try:\r\n",
        "        log_msgs(\"INFO\",'Create_Generic_Entity - Dummy entity: %s' % dummy)\r\n",
        "        _qualifiedname = 'dummy://%s' % dummy['uniqueAttributes']['qualifiedName']\r\n",
        "        output_guid = search_entities_byQuilifiedName(_qualifiedname)\r\n",
        "        if output_guid==None:\r\n",
        "            attributes = {}\r\n",
        "            qualifiedName = dummy['uniqueAttributes']['qualifiedName']\r\n",
        "            attributes[\"purview_qualifiedName\"]= dummy['uniqueAttributes']['qualifiedName']\r\n",
        "            typeName = \"\"\r\n",
        "            if \"typeName\" in dummy['uniqueAttributes']:\r\n",
        "                typeName = dummy['uniqueAttributes']['typeName']\r\n",
        "            if \"source\" in dummy['uniqueAttributes']:\r\n",
        "                attributes[\"original_source\"]= dummy['uniqueAttributes']['source']\r\n",
        "            tmepname = qualifiedName.split('/')\r\n",
        "            Name= tmepname[len(tmepname)-1]\r\n",
        "            if \"Name\" in dummy['uniqueAttributes']:\r\n",
        "                Name = dummy['uniqueAttributes']['Name']\r\n",
        "            if \"name\" in dummy['uniqueAttributes']:\r\n",
        "                Name = dummy['uniqueAttributes']['name']\r\n",
        "\r\n",
        "            generic_entity = AtlasEntity(\r\n",
        "                name = Name,\r\n",
        "                qualified_name = _qualifiedname,\r\n",
        "                typeName = \"purview_custom_connector_generic_entity\",\r\n",
        "                attributes = attributes,\r\n",
        "                guid = gt.get_guid()\r\n",
        "                )\r\n",
        "            upload_results = client.upload_entities(batch=[generic_entity])\r\n",
        "            if 'mutatedEntities' in upload_results:\r\n",
        "                if 'CREATE' in upload_results['mutatedEntities']:\r\n",
        "                    if len(upload_results['mutatedEntities']['CREATE']) >0:\r\n",
        "                        log_msgs(\"INFO\",'Create_Generic_Entity: Entities Created/Updated')\r\n",
        "                        log_msgs(\"INFO\",'Create_Generic_Entity: %s' % upload_results)\r\n",
        "                        return upload_results['mutatedEntities']['CREATE'][0]['guid']\r\n",
        "                    else:\r\n",
        "                        log_msgs(\"ERROR\",'Create_Generic_Entity: Fail to retrieve gui')\r\n",
        "                        log_msgs(\"ERROR\",json.dump(upload_results))\r\n",
        "                        return None\r\n",
        "                else:\r\n",
        "                    log_msgs(\"ERROR\",'Create_Generic_Entity: Fail to retrieve CREATE')\r\n",
        "                    log_msgs(\"ERROR\",json.dump(upload_results))\r\n",
        "                    return None\r\n",
        "            log_msgs(\"ERROR\",'Create_Generic_Entity: Fail to retrieve mutatedEntities')\r\n",
        "            log_msgs(\"ERROR\", json.dump(upload_results))\r\n",
        "            return None\r\n",
        "        else:\r\n",
        "            return output_guid\r\n",
        "    except Exception as e:\r\n",
        "      log_msgs(\"ERROR\",'Create_Generic_Entity: %s' % (str(e)))\r\n",
        "    return None\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def Load_Entity_Json(json_file):\r\n",
        "   try:\r\n",
        "    purview_load_entities=[]\r\n",
        "    for i in json_file:\r\n",
        "        json_obj = json.loads(i)\r\n",
        "        json_obj\r\n",
        "        purview_load_entities.append(json_obj)\r\n",
        "            \r\n",
        "    upload_results = client.upload_entities(batch=purview_load_entities)\r\n",
        "    log_msgs(\"INFO\",'Entities Created/Updated')\r\n",
        "    #print(json.dumps(upload_results, indent=2))\r\n",
        "    return True\r\n",
        "   except Exception as e:\r\n",
        "      log_msgs(\"ERROR\",'Load_Entity_Json: %s' % (str(e)))\r\n",
        "   return False\r\n",
        "\r\n",
        "def Load_Entity_Json_fromJson(_json):\r\n",
        "   try:\r\n",
        "    purview_load_entities=[]\r\n",
        "    for i in _json:\r\n",
        "        purview_load_entities.append(i)\r\n",
        "    \r\n",
        "    log_msgs(\"INFO\",(purview_load_entities))\r\n",
        "    upload_results = client.upload_entities(batch=purview_load_entities)\r\n",
        "    log_msgs(\"INFO\",'Entities Created/Updated')\r\n",
        "#    print(json.dumps(upload_results, indent=2))\r\n",
        "    return True\r\n",
        "   except Exception as e:\r\n",
        "      log_msgs(\"ERROR\",'Load_Entity_Json_fromJson: %s' % (str(e)))\r\n",
        "   return False\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "def Build_Entity_Json(_json):\r\n",
        "    \r\n",
        "    _parent = gt.get_guid()\r\n",
        "    my_parents={}\r\n",
        "    final_json = []\r\n",
        "    rel_obj = {}\r\n",
        "    try:\r\n",
        "        for i in _json:\r\n",
        "            _qualifiedname=None\r\n",
        "            _typename = None\r\n",
        "            json_obj = json.loads(i)\r\n",
        "            try:\r\n",
        "                if 'typeName' in json_obj:\r\n",
        "                    _typename = json_obj['typeName']\r\n",
        "                if _typename == None:\r\n",
        "                    log_msgs('ERROR','JSON dont have typeName of the entity')\r\n",
        "                    return False\r\n",
        "            except:\r\n",
        "                log_msgs('ERROR','JSON dont have typeName of the entity')\r\n",
        "                return False\r\n",
        "            try:\r\n",
        "                _qualifiedname = json_obj['attributes']['qualifiedName']\r\n",
        "            except:\r\n",
        "                log_msgs('ERROR','JSON dont have attributes/qualifiedName of the entity')\r\n",
        "                return False\r\n",
        "\r\n",
        "            if _qualifiedname != None and _typename != None:\r\n",
        "                entity = client.get_entity(qualifiedName=_qualifiedname,typeName=_typename)\r\n",
        "                if len(entity) > 0:\r\n",
        "                    entity_guid = entity[\"entities\"][0][\"guid\"]\r\n",
        "                    print(entity_guid)\r\n",
        "                    json_obj['guid'] = entity_guid\r\n",
        "                    my_parents[_typename]=entity_guid\r\n",
        "                else:\r\n",
        "                    if not 'guid' in json_obj:\r\n",
        "                        json_obj['guid'] = gt.get_guid()\r\n",
        "                    my_parents[_typename]=json_obj['guid']\r\n",
        "\r\n",
        "                if Get_Outputs(json_obj):\r\n",
        "                    for each in json_obj['attributes']['outputs']:\r\n",
        "                        _qualifiedname = each['uniqueAttributes']['qualifiedName']\r\n",
        "                        dummyEntities.append('dummy://%s' % _qualifiedname)\r\n",
        "                        output_guid = search_entities_byQuilifiedName(_qualifiedname)\r\n",
        "                        if output_guid==None:\r\n",
        "                            refguid = Create_Generic_Entity(each) \r\n",
        "                            if refguid != None:\r\n",
        "                                each['uniqueAttributes']['guid'] = refguid\r\n",
        "                                rel_obj[_qualifiedname] = refguid\r\n",
        "                            else:\r\n",
        "                                log_msgs(\"ERROR\",'Build_Entity_Json - output - results: Can\\'t Create Dummy '.join(each))\r\n",
        "                                return False\r\n",
        "                        else:\r\n",
        "                            each['uniqueAttributes']['guid'] = output_guid\r\n",
        "                            rel_obj[_qualifiedname] = output_guid\r\n",
        "\r\n",
        "                if Get_Inputs(json_obj):\r\n",
        "                    for each in json_obj['attributes']['inputs']:\r\n",
        "                        _qualifiedname = each['uniqueAttributes']['qualifiedName']\r\n",
        "                        dummyEntities.append('dummy://%s' % _qualifiedname)\r\n",
        "                        input_guid = search_entities_byQuilifiedName(_qualifiedname)\r\n",
        "                        if input_guid==None:\r\n",
        "                            refguid = Create_Generic_Entity(each) \r\n",
        "                            if refguid != None:\r\n",
        "                                each['uniqueAttributes']['guid'] = refguid\r\n",
        "                                rel_obj[_qualifiedname] = refguid\r\n",
        "                            else:\r\n",
        "                                log_msgs(\"ERROR\",'Build_Entity_Json - Input - results: Can\\'t Create Dummy '.join(each))\r\n",
        "                                return False\r\n",
        "                        else:\r\n",
        "                            each['uniqueAttributes']['guid'] = input_guid\r\n",
        "                            rel_obj[_qualifiedname] = input_guid\r\n",
        "\r\n",
        "\r\n",
        "                if Get_Rel_Inputs(json_obj):\r\n",
        "                    for each in json_obj['relationshipAttributes']['inputs']:\r\n",
        "                        _qualifiedname = each['qualifiedName']\r\n",
        "                        each['guid'] = rel_obj[_qualifiedname]\r\n",
        "\r\n",
        "                if Get_Rel_Outputs(json_obj):\r\n",
        "                    for each in json_obj['relationshipAttributes']['outputs']:\r\n",
        "                        _qualifiedname = each['qualifiedName']\r\n",
        "                        each['guid'] = rel_obj[_qualifiedname]\r\n",
        "\r\n",
        "                if Get_Rel_Parents(json_obj):\r\n",
        "                    json_obj['relationshipAttributes']['parent']['guid'] = my_parents[json_obj['relationshipAttributes']['parent']['typeName']]\r\n",
        "                final_json.append(json_obj)\r\n",
        "            else:\r\n",
        "                return False\r\n",
        "    except Exception as e:\r\n",
        "        log_msgs(\"ERROR\",'Build_Entity_Json: %s' % (str(e)))\r\n",
        "        return False\r\n",
        "    try:\r\n",
        "        Load_Entity_Json_fromJson(final_json)\r\n",
        "        return True\r\n",
        "    except Exception as e:\r\n",
        "        log_msgs(\"ERROR\",'Build_Entity_Json: %s' % (str(e)))\r\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "havefiles = True\r\n",
        "inicialnumfiles = 0\r\n",
        "dummyEntities = []\r\n",
        "while havefiles:\r\n",
        "    havefiles = False\r\n",
        "    files = mssparkutils.fs.ls(adls_home)\r\n",
        "    numoffiles = len(files)\r\n",
        "    processedfiles = 0\r\n",
        "    failfiles=0\r\n",
        "    for file in files:\r\n",
        "        if file.size > 0:\r\n",
        "            havefiles = True\r\n",
        "            i=0\r\n",
        "            filepath = \"\"\r\n",
        "            fileparts = file.path.split('/')\r\n",
        "            for filepart in fileparts:\r\n",
        "                if i < len(fileparts)-1:\r\n",
        "                    filepath+='%s/' % filepart\r\n",
        "                i+=1\r\n",
        "            \r\n",
        "            filepath='%s/%s' % (adls_processed,file.name)\r\n",
        "            load_json = False\r\n",
        "            readComplexJSONDF=None\r\n",
        "            try:\r\n",
        "                readComplexJSONDF = spark.read.option(\"multiLine\",\"true\").json(file.path)\r\n",
        "                load_json=True\r\n",
        "            except Exception as e:\r\n",
        "                log_msgs('ERROR','Invalid Json: %s /r %s' % file.path,e.args[0])\r\n",
        "\r\n",
        "            if load_json:\r\n",
        "                j = readComplexJSONDF.toJSON().collect()\r\n",
        "                log_msgs('INFO','Loading File: %s' % file.path)\r\n",
        "                if Build_Entity_Json(j):\r\n",
        "                    try:\r\n",
        "                        deletfile = mssparkutils.fs.rm(filepath)\r\n",
        "                        \r\n",
        "                    except:\r\n",
        "                        log_msgs('INFO','No file to delete')\r\n",
        "                    movefile = mssparkutils.fs.mv(src=file.path,dest=filepath)\r\n",
        "                    processedfiles+=1\r\n",
        "                else:\r\n",
        "                    failfiles+=1\r\n",
        "    if failfiles > 0  and processedfiles == 0:\r\n",
        "        print('Exit all files loaded')\r\n",
        "        break\r\n",
        "if len(dummyEntities) > 0:\r\n",
        "    for dummyEntitie in dummyEntities:\r\n",
        "        removeDummyEntity(dummyEntitie)"
      ]
    }
  ]
}