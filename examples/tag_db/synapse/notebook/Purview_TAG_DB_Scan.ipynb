{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "blob_container_name = \"\"\r\n",
        "blob_account_name = \"\"\r\n",
        "blob_relative_path = \"\"\r\n",
        "app_name = \"\"\r\n",
        "blob_processed=\"\"\r\n",
        "out_file=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Import All dependencies Libraries\r\n",
        "Make sure you import either to the cluster as workspace level or as sessionm the PyApacheAtlas packages. All the others are native."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import json\r\n",
        "import os\r\n",
        "# PyApacheAtlas packages\r\n",
        "# for using guid generator to garantee unid guids\r\n",
        "from pyapacheatlas.core.util import GuidTracker\r\n",
        "from notebookutils import mssparkutils\r\n",
        "from pyspark.conf import SparkConf\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Setting up program variables\r\n",
        "    - Logger: Use to logg debuging information\r\n",
        "    - mylogger: Object use to log\r\n",
        "    - adls_home: Used for the relative path for the files used by the Notebook\r\n",
        "    - adls_processed: Folder where processed files are putted after Notebook finishe processing the file\r\n",
        "    - adls_out_home: Folder where the output json used to load on purview is generated\r\n",
        "    - gt: Object responsible to track the unique identities for the Json objects to load onto Purview\r\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "#Setting up variable for loging.\r\n",
        "my_jars = os.environ.get(\"SPARK_HOME\")\r\n",
        "myconf = SparkConf()\r\n",
        "myconf.set(\"spark.jars\",\"%s/jars/log4j-1.2.17.jar\" % my_jars)\r\n",
        "spark = SparkSession\\\r\n",
        " .builder\\\r\n",
        " .appName(\"DB2_Test\")\\\r\n",
        " .config(conf = myconf) \\\r\n",
        " .getOrCreate()\r\n",
        "\r\n",
        "Logger= spark._jvm.org.apache.log4j.Logger\r\n",
        "mylogger = Logger.getLogger(app_name)\r\n",
        "#file path inicializer\r\n",
        "adls_home = 'abfss://%s@%s.dfs.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\r\n",
        "adls_processed = 'abfss://%s@%s.dfs.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_processed)\r\n",
        "adls_out_home = 'abfss://%s@%s.dfs.core.windows.net/%s' % (blob_container_name, blob_account_name, out_file)\r\n",
        "#inicialize guid tracker to garantee unique guids for the purview objects\r\n",
        "gt = GuidTracker()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Log Function\r\n",
        "Function write booth on the spark Server logs and output on the nootebook for debug\r\n",
        "    - msg_type: Type of mssage to write (ERROR or INFO)\r\n",
        "    - msg: Message to be logged\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "#function to simplify loging on files and on screen.\r\n",
        "def log_msgs(msg_type,msg):\r\n",
        "        \r\n",
        "        if msg_type.upper() == \"ERROR\":\r\n",
        "            print('ERROR: %s' % msg)\r\n",
        "            mylogger.error(msg)\r\n",
        "        else:\r\n",
        "            print('INFO: %s' % msg)\r\n",
        "            mylogger.info(\"Fim\")\r\n",
        "           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## All TAG DB Classes Definitions\r\n",
        "Used to read from XML and transform into the Json to be loaded into Purview\r\n",
        "    - AFDatabase\r\n",
        "    - AFElement\r\n",
        "    - AFAttribute\r\n",
        "    - AFAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "class AFBaseObject:\r\n",
        "    \"\"\"\r\n",
        "    Base Class fot the OSI PI metadata Objects,\r\n",
        "    provide a methond that is common for all other classes\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        self.attributes= {'attributes':{}}\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Generically creates a relationship with another data type\r\n",
        "\r\n",
        "    :param str nameElement:\r\n",
        "    Name that the element will have to the current Data Asset\r\n",
        "    e.g. \"Database\", \"Parent\", \"Child\", \"Group\"...\r\n",
        "\r\n",
        "    :param str typeElement:\r\n",
        "    Name of the type fo the element that it is creating the relationship\r\n",
        "\r\n",
        "    :param str idElement:\r\n",
        "    Guid fo the object that is creating the relationship to.\r\n",
        "\r\n",
        "    :param str relationShipType::\r\n",
        "    Name of the type of the relationship being created\r\n",
        "    \"\"\"\r\n",
        "    def addRelationship(self,nameElement, typeElement, idElement,relationShipType):\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]={}\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['guid']=idElement\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['typeName']= typeElement\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['entityStatus']= \"ACTIVE\"\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['displayText']= nameElement\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['relationshipType']= relationShipType\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['relationshipStatus']= \"ACTIVE\"\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['relationshipAttributes']={}\r\n",
        "        self.attributes['relationshipAttributes'][nameElement]['relationshipAttributes']['typeName']=relationShipType\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Return the class attributes as a dictionary (json like) to be \r\n",
        "    consumed by any API\r\n",
        "    \"\"\"\r\n",
        "    def toJson(self):\r\n",
        "        return self.attributes\r\n",
        "    \r\n",
        "    def fixDate(self, date):\r\n",
        "        if date is None:\r\n",
        "            return ''\r\n",
        "        else:\r\n",
        "            return date.replace('Z','.0000000Z')\r\n",
        "    \r\n",
        "    def removeNulls(self, field, isnumber=False):\r\n",
        "        if field is None:\r\n",
        "            if isnumber:\r\n",
        "                return 0\r\n",
        "            else:\r\n",
        "                return ''\r\n",
        "        else:\r\n",
        "            if field == '':\r\n",
        "                if isnumber:\r\n",
        "                    return 0\r\n",
        "                else:\r\n",
        "                    return ''\r\n",
        "        return field\r\n",
        "    \r\n",
        "class AFDatabase(AFBaseObject):\r\n",
        "    \"\"\"\r\n",
        "    AFDatabase Data Asset Type Definition, will hold all the metadata information for\r\n",
        "    a OSI PI AFDatabase data asset\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Inicialize the class with all the attributes needed\r\n",
        "\r\n",
        "    :param str name:\r\n",
        "    Name that will be using for the data asset\r\n",
        "\r\n",
        "    :param str description:\r\n",
        "    description of the data asset\r\n",
        "\r\n",
        "    :param str defaultpiserver:\r\n",
        "    Name of the Default OSI PI Server\r\n",
        "\r\n",
        "    :param str defaultpiserverid:\r\n",
        "    ID of the sefault OSI PI server\r\n",
        "\r\n",
        "    :param str guid:\r\n",
        "    Unique identifier of the Data Asset.\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,name=None, description=None,defaultpiserver=None, defaultpiserverid=None,guid=None):\r\n",
        "        self.name = self.removeNulls(name)\r\n",
        "        self.description= self.removeNulls(description)\r\n",
        "        self.defaultpiserver = self.removeNulls(defaultpiserver)\r\n",
        "        self.defaultpiserverid = self.removeNulls(defaultpiserverid)\r\n",
        "        #unique Identifier build based on the hierarchical patr AFDatabase-Name\r\n",
        "        self.qualifiedName = 'osipi://%s/%s' % (self.defaultpiserver,self.name)\r\n",
        "        self.guid = guid\r\n",
        "        self.typeName= 'afdatabase'\r\n",
        "        self.attributes = {'attributes':{}}\r\n",
        "        self.attributes['attributes']['name']=self.name\r\n",
        "        self.attributes['guid']=guid\r\n",
        "        self.attributes['attributes']['description']=self.description\r\n",
        "        self.attributes['attributes']['DefaultPIServer']=self.defaultpiserver\r\n",
        "        self.attributes['attributes']['DefaultPIServerID']=self.defaultpiserverid\r\n",
        "        self.attributes['attributes']['qualifiedName'] = self.qualifiedName\r\n",
        "        self.attributes['typeName']= 'afdatabase'\r\n",
        "        self.attributes['relationshipAttributes'] = {}\r\n",
        "    \r\n",
        "\r\n",
        "class AFElemento(AFBaseObject):\r\n",
        "    \"\"\"\r\n",
        "    AFElement Data Asset Type Definition, will hold all the metadata information for\r\n",
        "    a OSI PI AFElement data asset, has a relationship with AFDatabase and can have childs as: \r\n",
        "      * AFElements ('Parent')\r\n",
        "      * AFAttribiute ('Attribute')\r\n",
        "      * AFAnalysis ('Analysis')\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Inicialize the class with all the attributes needed\r\n",
        "\r\n",
        "    :param str guid:\r\n",
        "    Unique identifier of the Data Asset.\r\n",
        "\r\n",
        "    :param str name:\r\n",
        "    Name that will be using for the data asset\r\n",
        "\r\n",
        "    :param str description:\r\n",
        "    description of the data asset\r\n",
        "\r\n",
        "    :param int isAnnotated:\r\n",
        "    Represent 0 if false and 1 if true\r\n",
        "\r\n",
        "    :param str template:\r\n",
        "    Name of the template that the AFElement use\r\n",
        "\r\n",
        "    :param AFDatabase database:\r\n",
        "    Database that the element belongs to\r\n",
        "\r\n",
        "    :param str comment:\r\n",
        "    Comment about AFElement\r\n",
        "\r\n",
        "    :param datetime  effectiveDate:\r\n",
        "    Effective data for the AFElement \r\n",
        "    (Dates are not coming with miliseconds needed to be fixed, make sure you system is not using miliseconds also\r\n",
        "    mkae the change if need it)\r\n",
        "\r\n",
        "    :param datatime obsoleteDate:\r\n",
        "    Date when the AFElement gets obsolete\r\n",
        "    (Dates are not coming with miliseconds needed to be fixed, make sure you system is not using miliseconds also\r\n",
        "    mkae the change if need it)\r\n",
        "\r\n",
        "    :param str  modifier:\r\n",
        "    AFElement modifier\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,guid=None, name=None, description=None,isAnnotated=None, template=None,database=None, comment=None\r\n",
        "        , effectiveDate=None, obsoleteDate=None, modifier=None):\r\n",
        "        self.name = self.removeNulls(name)\r\n",
        "        self.description= self.removeNulls(description)\r\n",
        "        #unique Identifier build based on the hierarchical patr AFDatabase-AFElement Name\r\n",
        "        self.qualifiedName = 'osipi://%s/%s/%s' % (database.defaultpiserver,database.name,self.name)\r\n",
        "        self.obsoleteDate = self.fixDate(date=obsoleteDate)\r\n",
        "        self.template=self.removeNulls(template)\r\n",
        "        self.comment=self.removeNulls(comment)\r\n",
        "        self.database= database\r\n",
        "        self.isAnnotated=self.removeNulls(isAnnotated)\r\n",
        "        self.effectiveDate=self.fixDate(date=effectiveDate)\r\n",
        "        self.attributes = {'attributes':{}}\r\n",
        "        self.modifier = self.removeNulls(modifier)\r\n",
        "        self.guid=guid\r\n",
        "        self.attributes['relationshipAttributes'] = {}\r\n",
        "        \r\n",
        "        self.attributes['attributes']['name']=self.name\r\n",
        "        self.attributes['guid']=self.guid\r\n",
        "        self.attributes['attributes']['description']=self.description\r\n",
        "        self.attributes['attributes']['ObsoleteDate']=self.obsoleteDate\r\n",
        "        self.attributes['attributes']['Template']=self.template\r\n",
        "        self.attributes['attributes']['Comment'] = self.comment\r\n",
        "        self.attributes['attributes']['IsAnnotated'] = self.isAnnotated\r\n",
        "        self.attributes['attributes']['EffectiveDate'] = self.effectiveDate\r\n",
        "        self.attributes['attributes']['qualifiedName'] = self.qualifiedName\r\n",
        "        self.attributes['attributes']['Modifier']=self.modifier\r\n",
        "        self.attributes['typeName']= 'afelement'\r\n",
        "        self.addRelationship('Database', self.database.typeName, self.database.guid,'afdatabase_afelement')\r\n",
        "    \r\n",
        "class AFAttribute(AFBaseObject):\r\n",
        "    \"\"\"\r\n",
        "    AFAttribute Data Asset Type Definition, will hold all the metadata information for\r\n",
        "    a OSI PI AFAttribute data asset has relationship with some other OSI PI data Assets:\r\n",
        "      * AFElements ('Parent Element')\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "     Inicialize the class with all the attributes needed\r\n",
        "\r\n",
        "    :param str guid:\r\n",
        "    Unique identifier of the Data Asset.\r\n",
        "\r\n",
        "    :param str name:\r\n",
        "    Name that will be using for the data asset\r\n",
        "\r\n",
        "    :param str description:\r\n",
        "    description of the data asset\r\n",
        "    \r\n",
        "    :param int isHidden:\r\n",
        "    If is a hidden attribute, 0=false 1=true\r\n",
        "\r\n",
        "    :param int isManualDataEntry:\r\n",
        "    If is a manual data entry attribute, 0=false 1=true\r\n",
        "\r\n",
        "    :param in isExcluded:\r\n",
        "    If is excluded attribute, 0=false 1=true\r\n",
        "    \r\n",
        "    :param in isConfigurationItem:\r\n",
        "    If is a configuration attribute, 0=false 1=true\r\n",
        "    \r\n",
        "    :param str trait:\r\n",
        "    Trait\r\n",
        "\r\n",
        "    :param str defaultUOM:\r\n",
        "    Default UOM\r\n",
        "    \r\n",
        "    :param str displayDigits:\r\n",
        "    # display digits\r\n",
        "\r\n",
        "    :param str _type:\r\n",
        "    Type \r\n",
        "\r\n",
        "    :param str typeQualifier:\r\n",
        "    Type quilifier\r\n",
        "    \r\n",
        "    :param str dataReference:\r\n",
        "    Reference date in string format\r\n",
        "    \r\n",
        "    :param str configString:\r\n",
        "    Configuration string \r\n",
        "    \r\n",
        "    :param AFDatabase database:\r\n",
        "    Parent AFDatabase\r\n",
        "\r\n",
        "    :param AFElement afelement:\r\n",
        "    Parent AFElement\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,guid=None, name=None, description=None,isHidden=None, isManualDataEntry=None,isExcluded=None, isConfigurationItem=None, trait=None, defaultUOM=None, displayDigits=None,\r\n",
        "    _type=None, typeQualifier=None, dataReference=None, configString=None,database = None,afelement=None):\r\n",
        "        self.name = self.removeNulls(name)\r\n",
        "        self.description= self.removeNulls(description)\r\n",
        "        #unique Identifier build based on the hierarchical patr AFDatabase-AFElement-Name\r\n",
        "        self.qualifiedName = 'osipi://%s/%s/%s/%s' % (database.defaultpiserver,database.name,afelement.name,self.name)\r\n",
        "        self.isHidden = 0 if self.removeNulls(isHidden).upper()=='FALSE' else 1\r\n",
        "        self.isManualDataEntry=0 if self.removeNulls(isManualDataEntry).upper()=='FALSE' else 1\r\n",
        "        self.isExcluded=0 if self.removeNulls(isExcluded).upper()=='FALSE' else 1\r\n",
        "        self.database= database\r\n",
        "        self.isConfigurationItem=0 if self.removeNulls(isConfigurationItem).upper()=='FALSE' else 1\r\n",
        "        self.trait=self.removeNulls(trait)\r\n",
        "        self.defaultUOM=self.removeNulls(defaultUOM)\r\n",
        "        self.displayDigits=self.removeNulls(field=displayDigits,isnumber=True)\r\n",
        "        self._type=self.removeNulls(_type)\r\n",
        "        self.typeQualifier=self.removeNulls(typeQualifier)\r\n",
        "        self.dataReference=self.removeNulls(dataReference)\r\n",
        "        self.configString=self.removeNulls(configString)\r\n",
        "        self.attributes = {'attributes':{}}\r\n",
        "        self.guid=guid\r\n",
        "        self.attributes['relationshipAttributes'] = {}\r\n",
        "\r\n",
        "        self.attributes['attributes']['name']=self.name\r\n",
        "        self.attributes['guid']=self.guid\r\n",
        "        self.attributes['attributes']['description']=self.description\r\n",
        "        self.attributes['attributes']['IsHidden'] = self.isHidden\r\n",
        "        self.attributes['attributes']['IsManualDataEntry'] = self.isManualDataEntry\r\n",
        "        self.attributes['attributes']['IsExcluded'] = self.isExcluded\r\n",
        "        self.attributes['attributes']['IsConfigurationItem'] = self.isConfigurationItem\r\n",
        "        self.attributes['attributes']['Trait'] = self.trait\r\n",
        "        self.attributes['attributes']['DefaultUOM'] = self.defaultUOM\r\n",
        "        self.attributes['attributes']['DisplayDigits'] = self.displayDigits\r\n",
        "        self.attributes['attributes']['Type'] = self._type\r\n",
        "        self.attributes['attributes']['TypeQualifier'] = self.typeQualifier\r\n",
        "        self.attributes['attributes']['DataReference'] = self.dataReference\r\n",
        "        self.attributes['attributes']['ConfigString'] = self.configString\r\n",
        "        self.attributes['attributes']['qualifiedName'] = self.qualifiedName\r\n",
        "        self.attributes['typeName']= 'afattribute'\r\n",
        "\r\n",
        "        #adding relatioship to the Parent AFElement\r\n",
        "        self.addRelationship('Parent Element', 'afelement', afelement.guid,'afelement_afattribute')\r\n",
        "\r\n",
        "\r\n",
        "class AFAnalysis(AFBaseObject):\r\n",
        "    \"\"\"\r\n",
        "    AFAnalysis Data Asset Type Definition, will hold all the metadata information for\r\n",
        "    a OSI PI AFAnalysis data asset has relationship with some other OSI PI data Assets:\r\n",
        "      * AFElements ('Reference Element')\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "     Inicialize the class with all the attributes needed\r\n",
        "\r\n",
        "    :param str guid:\r\n",
        "    Unique identifier of the Data Asset.\r\n",
        "\r\n",
        "    :param str name:\r\n",
        "    Name that will be using for the data asset\r\n",
        "\r\n",
        "    :param str description:\r\n",
        "    description of the data asset\r\n",
        "    \r\n",
        "    :param in template:\r\n",
        "    Template used for the AFAnalysis\r\n",
        "    \r\n",
        "    :param str caseTemplate:\r\n",
        "    Case Template\r\n",
        "\r\n",
        "    :param str outputTime:\r\n",
        "    Output time\r\n",
        "    \r\n",
        "    :param str status:\r\n",
        "    Analysis Status\r\n",
        "\r\n",
        "    :param str publishResults:\r\n",
        "    Publish Results\r\n",
        "\r\n",
        "    :param str priority:\r\n",
        "    Priority\r\n",
        "    \r\n",
        "    :param str maxQueueSize:\r\n",
        "    Max Queue Size\r\n",
        "    \r\n",
        "    :param str groupID:\r\n",
        "    Group ID\r\n",
        "    \r\n",
        "    :param str target:\r\n",
        "    Target\r\n",
        "\r\n",
        "    :param AFDatabase database:\r\n",
        "    Parent AFDatabase\r\n",
        "\r\n",
        "    :param AFElement afelement:\r\n",
        "    Parent AFElement\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,guid=None, name=None, description=None,template=None, caseTemplate=None,outputTime=None, status=None, publishResults=None, priority=None, maxQueueSize=None,\r\n",
        "    groupID=None, target=None,database = None,afelement=None):\r\n",
        "        self.name = self.removeNulls(name)\r\n",
        "        self.description= self.removeNulls(description)\r\n",
        "        #unique Identifier build based on the hierarchical patr AFDatabase-AFElement-Name\r\n",
        "        self.qualifiedName = 'osipi://%s/%s/%s/%s' % (database.defaultpiserver,database.name,afelement.name,self.name)\r\n",
        "        self.template = self.removeNulls(template)\r\n",
        "        self.caseTemplate=self.removeNulls(caseTemplate)\r\n",
        "        self.publishResults=0 if self.removeNulls(publishResults).upper()=='FALSE' else 1\r\n",
        "        self.database= database\r\n",
        "        self.outputTime=self.removeNulls(outputTime)\r\n",
        "        self.status=self.removeNulls(status)\r\n",
        "        self.priority=self.removeNulls(priority)\r\n",
        "        self.maxQueueSize=self.removeNulls(field=maxQueueSize,isnumber=True)\r\n",
        "        self.groupID=self.removeNulls(field=groupID, isnumber=True)\r\n",
        "        self.attributes = {'attributes':{}}\r\n",
        "        self.guid=guid\r\n",
        "        self.attributes['relationshipAttributes'] = {}\r\n",
        "\r\n",
        "        self.attributes['attributes']['name']=self.name\r\n",
        "        self.attributes['guid']=self.guid\r\n",
        "        self.attributes['attributes']['description']=self.description\r\n",
        "        self.attributes['attributes']['Template'] = self.template\r\n",
        "        self.attributes['attributes']['CaseTemplate'] = self.caseTemplate\r\n",
        "        self.attributes['attributes']['PublishResults'] = self.publishResults\r\n",
        "        self.attributes['attributes']['OutputTime'] = self.outputTime\r\n",
        "        self.attributes['attributes']['Status'] = self.status\r\n",
        "        self.attributes['attributes']['Priority'] = self.priority\r\n",
        "        self.attributes['attributes']['MaxQueueSize'] = self.maxQueueSize\r\n",
        "        self.attributes['attributes']['GroupID'] = self.groupID\r\n",
        "        self.attributes['attributes']['qualifiedName'] = self.qualifiedName\r\n",
        "        self.attributes['typeName']= 'afanalysis'\r\n",
        "\r\n",
        "        self.addRelationship('Reference Element', 'afelement', afelement.guid,'afelement_afanalysis')\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Function to hlep check if Element exist in the Dictionary\r\n",
        "Check if element exists and send empty if it dos not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def get_element(name=None,dictionary=None):\r\n",
        "    if name in dictionary:\r\n",
        "        return dictionary[name]\r\n",
        "    return ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Recursive Function the iterate over the AFElement hierarchy\r\n",
        "Loop through all AFElements adding the hierarcgy into the json to be loaded and recreated ad relationship into Purview "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "#Function used to transverse the hierarchical tree and create the AFElements and it relationships\r\n",
        "#can be use recursively\r\n",
        "def get_AFElement(db=None, parent=None, element=None):\r\n",
        "    afelement = None\r\n",
        "    if 'Name' in element:\r\n",
        "        #condition to AFElements with parents\r\n",
        "        comment = None\r\n",
        "        if 'Comment' in element:\r\n",
        "            comment=get_element(name='Comment',dictionary= element)\r\n",
        "\r\n",
        "        afelement = AFElemento(\r\n",
        "            guid=gt.get_guid(), \r\n",
        "            name= get_element(name='Name',dictionary= element), \r\n",
        "            description= get_element(name='Description',dictionary= element),\r\n",
        "            isAnnotated= 1 if get_element(name='IsAnnotated',dictionary= element)=='True' else 0, \r\n",
        "            template= get_element(name='Template',dictionary= element),\r\n",
        "            database=db, \r\n",
        "            comment=comment, \r\n",
        "            effectiveDate= get_element(name='EffectiveDate',dictionary= element), \r\n",
        "            obsoleteDate=get_element(name='ObsoleteDate',dictionary= element),\r\n",
        "            modifier = get_element(name='Modifier',dictionary= element)\r\n",
        "        )\r\n",
        "        if parent != None:\r\n",
        "            #adding Parent relationship\r\n",
        "            afelement.addRelationship(\r\n",
        "                nameElement='Parent',\r\n",
        "                typeElement='afelement', \r\n",
        "                idElement = parent.guid,\r\n",
        "                relationShipType='afelement_afelement')\r\n",
        "        #Add AFElement for the list of entities to be loaded into Purview\r\n",
        "        purview_load_entities.append(afelement.toJson())\r\n",
        "    #validating is AFElement has child AFElement\r\n",
        "    if 'AFElement' in element:\r\n",
        "        #if it is a list of AFElements\r\n",
        "        if type(element['AFElement']) is list:\r\n",
        "            for item in element['AFElement']:\r\n",
        "                if not type(item) is list:\r\n",
        "                    try:\r\n",
        "                        get_AFElement(db=db,parent=afelement ,element=item)\r\n",
        "                    except:\r\n",
        "                        #print(item.keys())\r\n",
        "                        errors=1\r\n",
        "                        print(item)\r\n",
        "        else:\r\n",
        "        #Only One AFElement\r\n",
        "            get_AFElement(db=db,parent= afelement ,element=element['AFElement'])\r\n",
        "    \r\n",
        "    get_AFAnalysis(db=db, afelement=afelement,element=element)\r\n",
        "\r\n",
        "    get_AFAttributes(db=db, afelement=afelement,element=element)\r\n",
        "\r\n",
        "def get_AFAnalysis(db=None, afelement=None, element=None):\r\n",
        "    #Check is ther is AF Analysis\r\n",
        "    if 'AFAnalysis' in element:\r\n",
        "        #If it is more the one\r\n",
        "        if type(element['AFAnalysis']) is list:\r\n",
        "            for attrib in element['AFAnalysis']:\r\n",
        "                analysis = set_AFAnalysis(analisys=element,database = db,afelement=afelement)\r\n",
        "                #Append the AFAnalysis to the list of Data Assets to be loaded into Purview\r\n",
        "                purview_load_entities.append(analysis.toJson())\r\n",
        "        else:\r\n",
        "        #Only one AFAnalysis\r\n",
        "            attrib = element['AFAnalysis']\r\n",
        "            analysis = set_AFAnalysis(analisys=element,database = db,afelement=afelement)\r\n",
        "            #Append the AFAnalysis to the list of Data Assets to be loaded into Purview\r\n",
        "            purview_load_entities.append(analysis.toJson())\r\n",
        "\r\n",
        "def get_AFAttributes(db=None, afelement=None, element=None):\r\n",
        "    #checking if AFElement has AFAttributes\r\n",
        "    if 'AFAttribute' in element:\r\n",
        "        #If it is a list of AFAttributes\r\n",
        "        if type(element['AFAttribute']) is list:\r\n",
        "            for attrib in element['AFAttribute']:\r\n",
        "                attribute = set_AFAttribute(attrib=element, database = db,afelement=afelement)\r\n",
        "                #Append the AFAttribute to the list of Data Assets to be loaded into Purview\r\n",
        "                purview_load_entities.append(attribute.toJson())\r\n",
        "        else:\r\n",
        "        #Only one AFAttribute\r\n",
        "            attrib = element['AFAttribute']\r\n",
        "            attribute = set_AFAttribute(attrib=element, database = db,afelement=afelement)\r\n",
        "            #Append the AFAttribute to the list of Data Assets to be loaded into Purview\r\n",
        "            purview_load_entities.append(attribute.toJson())\r\n",
        "\r\n",
        "\r\n",
        "def set_AFAttribute(attrib=None, database=None,afelement=None):\r\n",
        "    return AFAttribute(\r\n",
        "                    guid=gt.get_guid(), name=get_element('Name',attrib), \r\n",
        "                    description=get_element('Description',attrib),isHidden=get_element('IsHidden',attrib), \r\n",
        "                    isManualDataEntry=get_element('IsManualDataEntry',attrib),isExcluded=get_element('IsExcluded',attrib), \r\n",
        "                    isConfigurationItem=get_element('IsConfigurationItem',attrib), trait=get_element('Trait',attrib), \r\n",
        "                    defaultUOM=get_element('DefaultUOM',attrib), displayDigits=get_element('DisplayDigits',attrib),\r\n",
        "                    _type=get_element('Type',attrib), typeQualifier=get_element('TypeQualifier',attrib), \r\n",
        "                    dataReference=get_element('DataReference',attrib), configString=get_element('ConfigString',attrib),\r\n",
        "                    database = database,afelement=afelement)\r\n",
        "\r\n",
        "def set_AFAnalysis(analisys, database, afelement):\r\n",
        "    return AFAnalysis(\r\n",
        "                guid=gt.get_guid(), name=analisys['Name'], \r\n",
        "                    description= get_element('Description',analisys),\r\n",
        "                    template= get_element('Template',analisys), caseTemplate=get_element('CaseTemplate',analisys),\r\n",
        "                    outputTime=get_element('OutputTime',analisys), status=get_element('Status',analisys), \r\n",
        "                    publishResults=get_element('PublishResults',analisys), priority=get_element('Priority',analisys), maxQueueSize=get_element('MaxQueueSize',analisys),\r\n",
        "                    groupID=get_element('GroupID',analisys), target=get_element('Target',analisys),\r\n",
        "                    database = database,afelement=afelement)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Function (load_tag_db_DataAssets) that Generate the Full Data Assets to be loaded into Purview\r\n",
        "Validate Top AF nodes to generate the the json objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "def load_tag_db_DataAssets(j):\r\n",
        "    \r\n",
        "    for i in j:\r\n",
        "        json_obj = json.loads(i)\r\n",
        "        #print(json_obj)\r\n",
        "        if 'AF' in json_obj:\r\n",
        "            #print('Found AF')\r\n",
        "            if 'AFDatabase' in json_obj['AF']:\r\n",
        "                if 'Name' in json_obj['AF'][\"AFDatabase\"]:\r\n",
        "                    #print('Found AFDatabase')\r\n",
        "                    if 'Description' in json_obj['AF'][\"AFDatabase\"]:\r\n",
        "                        DefaultPIServer=''\r\n",
        "                        DefaultPIServerID=''\r\n",
        "                        if 'AFExtendedProperty' in json_obj['AF'][\"AFDatabase\"]:\r\n",
        "                            for l in json_obj['AF'][\"AFDatabase\"]['AFExtendedProperty']:\r\n",
        "                                if 'Name' in l:\r\n",
        "                                    if l['Name']=='DefaultPIServer':\r\n",
        "                                        DefaultPIServer= l[\"Value\"]\r\n",
        "                                    if l['Name']=='DefaultPIServerID':\r\n",
        "                                        DefaultPIServerID = l[\"Value\"]\r\n",
        "                        db = AFDatabase(guid=gt.get_guid(),\r\n",
        "                            name=json_obj['AF'][\"AFDatabase\"]['Name'],\r\n",
        "                            description=json_obj['AF'][\"AFDatabase\"]['Description'],\r\n",
        "                            defaultpiserver=DefaultPIServer,\r\n",
        "                            defaultpiserverid=DefaultPIServerID\r\n",
        "                        )\r\n",
        "                        #print(db.toJson())   \r\n",
        "                        purview_load_entities.append(db.toJson())\r\n",
        "                    if 'AFElement' in json_obj['AF'][\"AFDatabase\"]:\r\n",
        "                        #print('Found AFElement')\r\n",
        "                        get_AFElement(db,None,json_obj['AF'][\"AFDatabase\"]['AFElement'])\r\n",
        "                    #print(purview_load_entities)\r\n",
        "                    now = datetime.now() # current date and time\r\n",
        "                    timestamp = now.strftime(\"%y%m%d%H%M%S%f\")\r\n",
        "                    json_value = json.dumps(purview_load_entities)\r\n",
        "                    mssparkutils.fs.put('%s/osipi-%s.json' % (adls_out_home,timestamp),json_value, True)\r\n",
        "                    return True\r\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Loop over all the files on the ADLS_HOME folder to generate all json objects to load into Purview\r\n",
        "Loop over all files, load one by one and move to processs folder after correctly proccessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "import traceback\r\n",
        "try:\r\n",
        "    havefiles = True\r\n",
        "    inicialnumfiles = 0\r\n",
        "    while havefiles:\r\n",
        "        havefiles = False\r\n",
        "        files = mssparkutils.fs.ls(adls_home)\r\n",
        "        numoffiles = len(files)\r\n",
        "        processedfiles = 0\r\n",
        "        failfiles=0\r\n",
        "        for file in files:\r\n",
        "            purview_load_entities=[]\r\n",
        "            if file.size > 0:\r\n",
        "                havefiles = True\r\n",
        "                i=0\r\n",
        "                filepath = \"\"\r\n",
        "                fileparts = file.path.split('/')\r\n",
        "                for filepart in fileparts:\r\n",
        "                    if i < len(fileparts)-1:\r\n",
        "                        filepath+='%s/' % filepart\r\n",
        "                    i+=1\r\n",
        "                \r\n",
        "                filepath='%s/%s' % (adls_processed,file.name)\r\n",
        "                load_json = False\r\n",
        "                readComplexJSONDF=None\r\n",
        "                try:\r\n",
        "                    print(file.path)\r\n",
        "                    readComplexJSONDF = spark.read.option(\"multiLine\",\"true\").json(file.path)\r\n",
        "                    load_json=True\r\n",
        "                    print('Finished Loading json')\r\n",
        "                except Exception as e:\r\n",
        "                    log_msgs('ERROR','Invalid Json: %s /r %s' % file.path,e.args[0])\r\n",
        "\r\n",
        "                if load_json:\r\n",
        "                    print('Start Loading Json')\r\n",
        "                    j = readComplexJSONDF.toJSON().collect()\r\n",
        "                    log_msgs('INFO','Loading File: %s' % file.path)\r\n",
        "                    if load_tag_db_DataAssets(j):\r\n",
        "                        print('Finished Loading File')\r\n",
        "                        try:\r\n",
        "                            deletfile = mssparkutils.fs.rm(filepath)\r\n",
        "                            \r\n",
        "                        except:\r\n",
        "                            log_msgs('INFO','No file to delete')\r\n",
        "                        movefile = mssparkutils.fs.mv(src=file.path,dest=filepath)\r\n",
        "                        processedfiles+=1\r\n",
        "                    else:\r\n",
        "                        failfiles+=1\r\n",
        "        if failfiles > 0  and processedfiles == 0:\r\n",
        "            print('Exit all files loaded')\r\n",
        "            break\r\n",
        "except  Exception as e:\r\n",
        "    traceback_lines = traceback.format_exc().splitlines()\r\n",
        "    log_msgs('ERROR',traceback_lines)"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}